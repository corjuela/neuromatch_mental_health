{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('/Users/gracehandley/Desktop/data_projects/neuromatch/joined_dataset.csv')\n",
    "data = data.drop(data.columns[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regular expression pattern for URLs\n",
    "url_pattern = r'(https?://\\S+)'\n",
    "\n",
    "# Function to extract URLs from text\n",
    "def extract_urls(text):\n",
    "    return re.findall(url_pattern, text)\n",
    "\n",
    "# Apply the function to extract URLs in 'text' column\n",
    "data['urls'] = data['text'].apply(extract_urls)\n",
    "\n",
    "found_urls = False\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    if urls:\n",
    "        print(f\"URLs found in row {index + 1}: {urls}\")\n",
    "        found_urls = True\n",
    "\n",
    "if not found_urls:\n",
    "    print(\"No URLs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "data['text'] = data['text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for special characters in data frame using regex\n",
    "pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "# Iterate over each row and check for special characters in 'text' variable\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    special_characters = re.findall(pattern, text)\n",
    "    \n",
    "    if special_characters:\n",
    "        print(f\"Special characters found in row {index + 1}: {special_characters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove special characters\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "data['text'] = data['text'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are punctuation marks in 'text' column\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    \n",
    "    if any(char in string.punctuation for char in text):\n",
    "        print(f\"Punctuation marks found in row {index + 1}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove punctuation marks from text\n",
    "def remove_punctuation(text):\n",
    "    return ''.join(char for char in text if char not in string.punctuation)\n",
    "\n",
    "data['text'] = data['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm URLs, special characters, and punctuation marks were removed\n",
    "found_urls = False\n",
    "found_special_chars = False\n",
    "found_punctuation = False\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    special_characters = re.findall(pattern, text)\n",
    "    urls = re.findall(url_pattern, text)\n",
    "\n",
    "    if urls:\n",
    "        print(f\"URLs found in row {index + 1}: {urls}\")\n",
    "        found_urls = True\n",
    "\n",
    "    if special_characters:\n",
    "        print(f\"Special characters found in row {index + 1}: {special_characters}\")\n",
    "        found_special_chars = True\n",
    "\n",
    "    if any(char in string.punctuation for char in text):\n",
    "        print(f\"Punctuation marks found in row {index + 1}: {text}\")\n",
    "        found_punctuation = True\n",
    "\n",
    "# Display confirmation messages\n",
    "if not found_urls:\n",
    "    print(\"No URLs found\")\n",
    "\n",
    "if not found_special_chars:\n",
    "    print(\"No special characters found\")\n",
    "\n",
    "if not found_punctuation:\n",
    "    print(\"No punctuation marks found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleandata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
